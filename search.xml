<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hello 海珠</title>
    <url>/2013/04/20/hello-world-1/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3>]]></content>
  </entry>
  <entry>
    <title>Linux命令操作</title>
    <url>/2019/04/20/Linux%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h4 id="1-pwd-查看当前光标所在的目录"><a href="#1-pwd-查看当前光标所在的目录" class="headerlink" title="1. pwd 查看当前光标所在的目录"></a>1. pwd 查看当前光标所在的目录</h4><p>显示从根目录/开始 <strong>绝对路径</strong><br>例如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu modules]# pwd</span><br><span class="line">/opt/modules</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h4 id="2-用户"><a href="#2-用户" class="headerlink" title="2. 用户"></a>2. 用户</h4><ul>
<li><code>root</code>   超级管理员  123456(密码)  <code>家目录是  /root</code></li>
<li><code>haizhu</code> 普通用户  界面创建   <code>家目录是 /home/haizhu</code></li>
</ul>
<p>默认系统是这样 除非指定用户的家目录为其他目录</p>
<p><strong>Linux系统的目录是从根目录开始</strong> <code>/</code></p>
<h4 id="3-ls查看"><a href="#3-ls查看" class="headerlink" title="3. ls查看"></a>3. ls查看</h4><ul>
<li><p><code>ls</code> 只显示该目录下的文件或文件夹的名称</p>
</li>
<li><p><code>ls -l</code>显示该目录下的文件或文件夹的明细信息 </p>
</li>
<li><p><code>ls -l &lt;==&gt; ll</code> 2个命令是等价的</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu modules]# ls -l /home</span><br><span class="line">total 8</span><br><span class="line">drwx------ 3 lighthouse lighthouse 4096 Apr  8 14:10 lighthouse</span><br><span class="line">drwx------ 2 shen       shen       4096 Apr  8 15:35 shen</span><br><span class="line">权限          用户       用户组             时间        名称</span><br></pre></td></tr></table></figure></li>
<li><p><code>ll -h</code> 查看文件的大小</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu flink]# ll -h /opt/modules/hadoop-2.6.0/</span><br><span class="line">total 60K</span><br><span class="line">drwxr-xr-x 2 20000 20000 4.0K Nov 14  2014 bin  (4.0K 表示bin文件大小）</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
<li><p><code>du -sh</code>  文件夹或文件大小</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">文件夹</span><br><span class="line">[root@haizhu flink]# du -sh /opt/modules/hadoop-2.6.0/</span><br><span class="line">320M    /opt/modules/hadoop-2.6.0/ (320M 表示hadoop-2.6.0文件夹大小)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">文件</span><br><span class="line">[root@haizhu flink]# du -sh  README.txt </span><br><span class="line">4.0K    README.txt</span><br></pre></td></tr></table></figure></li>
<li><p><code>ll -rt</code> 想要找出最新的文件或文件夹 按照时间升序排列</p>
</li>
<li><p><code>ll -a</code> 查看隐藏文件夹或文件  <strong>隐藏是以.开始</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu flink]# ll -a</span><br><span class="line">total 608</span><br><span class="line">drwxr-xr-x 10  502 games   4096 Jan 10  2021 .</span><br><span class="line">drwxr-xr-x 11 root root    4096 Apr 22 11:41 ..</span><br><span class="line">drwxr-xr-x  2  502 games   4096 Apr 22 11:40 bin</span><br><span class="line">drwxr-xr-x  2  502 games   4096 Apr 22 12:45 conf</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h4 id="4-cd切换目录"><a href="#4-cd切换目录" class="headerlink" title="4. cd切换目录"></a>4. cd切换目录</h4><h5 id="cd-home-切换到-home目录"><a href="#cd-home-切换到-home目录" class="headerlink" title="cd /home : 切换到 /home目录"></a><code>cd /home</code> : 切换到 <code>/home</code>目录</h5></li>
<li><p><code>cd</code> 和 <code>cd ~</code>  2种切家目录  <strong>~是家目录标识</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu modules]# cd </span><br><span class="line">[root@haizhu ~]# pwd</span><br><span class="line">/root</span><br><span class="line">[root@haizhu ~]# cd ~</span><br><span class="line">[root@haizhu ~]# pwd</span><br><span class="line">/root</span><br><span class="line">[root@haizhu ~]#</span><br></pre></td></tr></table></figure></li>
<li><p><code>cd /root</code> 用户的家目录的绝对路径</p>
</li>
<li><p><code>cd -</code>   回到上一次目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu opt]# cd /usr/</span><br><span class="line">[root@haizhu usr]# cd /opt/modules/</span><br><span class="line">[root@haizhu modules]# cd -</span><br><span class="line">/usr</span><br><span class="line">[root@haizhu usr]#</span><br></pre></td></tr></table></figure></li>
<li><p><code>cd ../</code>  回退上一层目录</p>
</li>
<li><p><code>cd ../../</code> 回退2个目录</p>
<h4 id="5-路径"><a href="#5-路径" class="headerlink" title="5. 路径"></a>5. 路径</h4></li>
<li><p>绝对路径 <code>/</code>根目录开始</p>
</li>
<li><p>相对路径 不以<code>/</code>开始</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@hadoop001 ~]# ls</span><br><span class="line">anaconda-ks.cfg  Downloads           Music     Templates</span><br><span class="line">Desktop          install.log         Pictures  Videos</span><br><span class="line">Documents        install.log.syslog  Public</span><br><span class="line">[root@hadoop001 ~]# cd Desktop/   相对</span><br><span class="line">[root@hadoop001 Desktop]# </span><br><span class="line"></span><br><span class="line">[root@hadoop001 ~]# cd /root/Desktop/ 绝对</span><br><span class="line">[root@hadoop001 Desktop]#</span><br></pre></td></tr></table></figure>
<h4 id="6-clear-清空屏幕"><a href="#6-clear-清空屏幕" class="headerlink" title="6.clear 清空屏幕"></a>6.clear 清空屏幕</h4><h4 id="7-创建文件夹"><a href="#7-创建文件夹" class="headerlink" title="7. 创建文件夹"></a>7. 创建文件夹</h4></li>
<li><p><code>mkdir data</code> 只能创建1个</p>
</li>
<li><p><code>mkdir -p data/1/2</code> 级联创建文件夹 <strong>串行</strong></p>
</li>
<li><p><code>mkdir 4 5 6</code> 创建4,5,6 3个<strong>并行</strong>文件夹</p>
</li>
</ul>
<h4 id="8-创建文件"><a href="#8-创建文件" class="headerlink" title="8.创建文件"></a>8.创建文件</h4><ul>
<li><code>touch data.log</code> 创建空文件</li>
<li><code>vi haizhu.log</code> 创建文件 </li>
</ul>
<h4 id="9-cp拷贝"><a href="#9-cp拷贝" class="headerlink" title="9. cp拷贝"></a>9. cp拷贝</h4><p><strong>2份 原有的还在</strong><br>1）文件拷贝<br><code>cp hai.log data/</code> 把<code>hai.log</code>文件拷贝到 <code>data/</code> 文件夹<br>2）文件夹拷贝<br><code>cp -r 7 6/</code> 文件夹拷贝 需要-r参数</p>
<h5 id="10-mv移动"><a href="#10-mv移动" class="headerlink" title="10. mv移动"></a>10. mv移动</h5><p><strong>1份 原有的到新位置</strong><br><code>mv data.log 6</code>               移动文件到新的地方 名称不变<br><code>mv data.log  6/data123.log</code>   移动文件到新的地方 名称变<br><code>mv 8 6</code> 移动文件夹</p>
<h4 id="11-命令帮助"><a href="#11-命令帮助" class="headerlink" title="11. 命令帮助"></a>11. 命令帮助</h4><p>1） <code>--help</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu flink]# ls --help</span><br><span class="line">Usage: ls [OPTION]... [FILE]...</span><br></pre></td></tr></table></figure>
<p>[]代表可以省略</p>
<h4 id="12-查看文件内容-log定位"><a href="#12-查看文件内容-log定位" class="headerlink" title="12. 查看文件内容 log定位"></a>12. 查看文件内容 log定位</h4><p>1）离线查看 </p>
<ul>
<li><code>cat</code> 文件内容一下子<strong>全部显示</strong>  适用<strong>字节内容较少</strong></li>
<li><code>more</code>文件内容<strong>一页一页</strong>的往下翻,按空格键往下 回退不了 按q退出   适用<strong>字节内容稍多的</strong> </li>
<li><code>less</code> 文件内容<strong>一行行</strong> 按箭头上下  按q退出</li>
</ul>
<p><em>查看内容多的文件ERROR经验方法</em></p>
<ul>
<li>假如文件超大 10M内<br>  <code>发送给电脑，通过sublime等工具全局搜索</code></li>
<li>假如文件100M+<br><code>cat install.log | grep -C 10 &quot;ERROR&quot;</code><br>表示：<code>install.log</code>文件中ERROR关键字上下文共20行</li>
<li>假如ERROR筛选的结果很多（比如10个ERROR以上）<br><code>cat install.log | grep -C 10 &quot;ERROR&quot; &gt; error.log</code><br>表示：<code>install.log</code>文件中ERROR关键字上下文共20行输出到<code>error.log</code>文件</li>
<li>注意：*<br><code>|</code> 管道符（衔接符）<br><code>grep</code> 过滤<br><code>grep -C 10</code> 上下文共20行<br><code>&gt;</code> 重定向输出到文件 <strong>覆盖</strong><br><code>&gt;&gt;</code> <strong>追加</strong></li>
</ul>
<p>2）实时查看 <code>tail</code><br><code>tail -f tail1.log</code><br><code>tail -F tail2.log</code></p>
<p>-F=-f+retry</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# echo "123" &gt;&gt; tail1.log  (把123追加到tail1.log文件）</span><br><span class="line">[root@hadoop001 ~]# echo "123" &gt;&gt; tail2.log </span><br><span class="line">[root@hadoop001 ~]# echo "123" （echo打印的意思）</span><br><span class="line">123</span><br><span class="line">[root@hadoop001 ~]# echo "4" &gt;&gt; tail1.log </span><br><span class="line">[root@hadoop001 ~]# echo "4" &gt;&gt; tail2.log</span><br></pre></td></tr></table></figure>
<p><strong>案例</strong><br>生产上 xxxx.log 100m 保留10份<br>xxxx.log<br>xxxx.log1<br>xxxx.log2<br>….<br>xxxx.log9<br>xxxx.log10</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv tail1.log tail1.log1 </span><br><span class="line">touch tail1.log</span><br><span class="line"></span><br><span class="line">mv tail2.log tail2.log1 </span><br><span class="line">touch tail2.log</span><br><span class="line">[root@hadoop001 ~]# echo "5" &gt;&gt; tail1.log</span><br><span class="line">[root@hadoop001 ~]# echo "5" &gt;&gt; tail2.log</span><br><span class="line"></span><br><span class="line">[root@hadoop001 ~]# tail -f tail1.log </span><br><span class="line">123</span><br><span class="line">4</span><br><span class="line"></span><br><span class="line">[root@hadoop001 ~]# tail -F tail2.log </span><br><span class="line">123</span><br><span class="line">4</span><br><span class="line">tail: `tail2.log' has become inaccessible: No such file or directory</span><br><span class="line">tail: `tail2.log' has appeared;  following end of new file</span><br><span class="line">5</span><br></pre></td></tr></table></figure>
<p><strong>说明-f 不够强大 文件只要被移走 就算新的一模一样 也不会实时监控<br>反之-F 强大 实时监控</strong><br>查看倒数50行 <code>tail -50f xxx.log</code></p>
<h4 id="13-alias-别名"><a href="#13-alias-别名" class="headerlink" title="13. alias 别名"></a>13. alias 别名</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# alias rd='cd /root/data'</span><br><span class="line">[root@hadoop001 ~]# </span><br><span class="line">[root@hadoop001 ~]# rd</span><br><span class="line">[root@hadoop001 ~]# pwd</span><br><span class="line">/root/data</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong><br>在另外一个会话窗口 rd命令找不到:<br>我们设置别名时为 当前session生效  为临时</p>
<p>如何做全局:环境变量里面设置</p>
<h5 id="14-全局环境变量和个人环境变量"><a href="#14-全局环境变量和个人环境变量" class="headerlink" title="14. 全局环境变量和个人环境变量"></a>14. 全局环境变量和个人环境变量</h5><ul>
<li>全局: 意味着所有人都可以使用<br><code>/etc/profile</code><br><code>source /etc/profile</code> </li>
</ul>
<p>其他用户也可以使用，只不过我们当前抛错,为权限错误</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# su - jepson</span><br><span class="line">[jepson@hadoop001 ~]$ rd</span><br><span class="line">-bash: cd: /root/ruozedata: Permission denied</span><br></pre></td></tr></table></figure>

<ul>
<li><p>个人:<br><code>~/.bash_profile</code><br><code>~/.bashrc</code><br>2种生效:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# source .bash_profile </span><br><span class="line">[root@hadoop001 ~]# . .bash_profile</span><br><span class="line">``` </span><br><span class="line">**未来习惯用哪个就哪个，</span><br><span class="line">但是不要忘记另外的存在，关键时要去看一下**</span><br><span class="line"></span><br><span class="line">*vi 文件时 拷贝内容必须为insert模式，否则可能会丢失复制信息*</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">### 14. rm 删除</span></span></span><br><span class="line">`rm data.log  `   文件 询问</span><br><span class="line">`rm -f tail1.log` 文件 不询问</span><br><span class="line">`rm -rf 6 `       文件夹 不询问</span><br><span class="line"></span><br><span class="line">**`rm -rf /` 生产上致命的，这个命令慎用**</span><br><span class="line"></span><br><span class="line">写shell脚本</span><br><span class="line">`xxxpath=/root/data`</span><br><span class="line">* =前后不能有空格</span><br><span class="line">* 赋值时不需要$,使用时需要$</span><br><span class="line"></span><br><span class="line">逻辑再赋值 有可能 xxxpath=</span><br><span class="line">`rm -rf $xxxpath/*`  ==&gt; `rm -rf /* `</span><br><span class="line">`rm -rf $&#123;xxxpath&#125;`</span><br><span class="line">`rm -rf xxxpath`</span><br><span class="line"></span><br><span class="line">**规避: 生产上凡是碰见rm -rf强制删除文件夹的 ，路径一定先判断存在不，不存在 就skip；就存在就rm**</span><br><span class="line"></span><br><span class="line">*怎么样逃避责任？*</span><br><span class="line">常规的链接</span><br><span class="line">* vpn 不会记录命令操作记录</span><br><span class="line">    history -c命令清空 同时删除家目录的.bash_history</span><br><span class="line">* 堡垒机 记录命令操作记录</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">### 15. history</span></span></span><br><span class="line">查看所有已经执行的命令</span><br><span class="line">`!5` 执行第五行已经执行的命令</span><br><span class="line"></span><br><span class="line">**补充: 当拿到1个已经存在的工作集群，通过history查看历史记录,帮助自己快速了解当前的集群环境**</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">### 16. 用户/用户组的常用命令</span></span></span><br><span class="line"></span><br><span class="line">1）用户</span><br><span class="line">```shell</span><br><span class="line">[root@hadoop001 ~]# ll /usr/sbin/user*</span><br><span class="line">-rwxr-x---. 1 root root 103096 Dec  8  2011 /usr/sbin/useradd</span><br><span class="line">-rwxr-x---. 1 root root  69560 Dec  8  2011 /usr/sbin/userdel</span><br><span class="line">-rws--x--x. 1 root root  42384 Aug 23  2010 /usr/sbin/userhelper</span><br><span class="line">-rwxr-x---. 1 root root  98680 Dec  8  2011 /usr/sbin/usermod</span><br><span class="line">-rwsr-xr-x. 1 root root   9000 Nov 23  2013 /usr/sbin/usernetctl</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加用户 <code>useradd ruoze</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# id ruoze</span><br><span class="line">uid=501(ruoze) gid=501(ruoze) groups=501(ruoze)</span><br><span class="line">	用户名称	      主组             所有组</span><br><span class="line">[root@hadoop001 ~]# ll /home/ruoze</span><br><span class="line">total 0</span><br><span class="line">[root@hadoop001 ~]# ll -a /home/ruoze</span><br><span class="line">total 28</span><br><span class="line">drwx------. 4 ruoze ruoze 4096 Jun 16 21:16 .</span><br><span class="line">drwxr-xr-x. 4 root  root  4096 Jun 16 21:16 ..</span><br><span class="line">-rw-r--r--. 1 ruoze ruoze   18 Jul 18  2013 .bash_logout</span><br><span class="line">-rw-r--r--. 1 ruoze ruoze  176 Jul 18  2013 .bash_profile</span><br><span class="line">-rw-r--r--. 1 ruoze ruoze  124 Jul 18  2013 .bashrc</span><br><span class="line">drwxr-xr-x. 2 ruoze ruoze 4096 Nov 12  2010 .gnome2</span><br><span class="line">drwxr-xr-x. 4 ruoze ruoze 4096 Jun 13 04:10 .mozilla</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><strong>记录在哪？</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# cat /etc/passwd</span><br><span class="line">ruoze:x:501:501::/home/ruoze:/bin/bash</span><br><span class="line"></span><br><span class="line">[root@hadoop001 ~]# cat /etc/group</span><br><span class="line">ruoze:x:501:</span><br></pre></td></tr></table></figure>
<ul>
<li><p>删除用户 <code>userdel ruoze</code><br>删除用户，会把passwd记录删除；同时假如该组没有其他用户，则删除该组<br>但是<strong>家目录还在</strong>,但是<strong>用户和用户组发生变革</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ll /home/</span><br><span class="line">total 8</span><br><span class="line">drwx------. 4 jepson jepson 4096 Jun 16 20:55 jepson</span><br><span class="line">drwx------. 4    501    501 4096 Jun 16 21:16 ruoze</span><br><span class="line">`</span><br></pre></td></tr></table></figure>
</li>
<li><p>再次创建 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# useradd ruoze</span><br><span class="line">useradd: warning: the home directory already exists.</span><br><span class="line">Not copying any file from skel directory into it.</span><br><span class="line">Creating mailbox file: File exists</span><br></pre></td></tr></table></figure>
<p>skel directory: <code>.bash*</code>所有的隐藏文件</p>
</li>
</ul>
<p>删除ruoze用户，切换到ruoze，会出现 <code>-bash-4.1$</code><br><strong>解决方法：恢复</strong><br><code>rm -rf /home/ruoze/.bash*</code><br><code>cp /etc/skel/.* /home/ruoze</code><br><code>chown ruoze:ruoze /etc/skel/.*</code><br>影响用户操作时的格式 </p>
<p>2）用户组</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ll &#x2F;usr&#x2F;sbin&#x2F;group*</span><br><span class="line">-rwxr-x---. 1 root root 54968 Dec  8  2011 &#x2F;usr&#x2F;sbin&#x2F;groupadd</span><br><span class="line">-rwxr-x---. 1 root root 46512 Dec  8  2011 &#x2F;usr&#x2F;sbin&#x2F;groupdel</span><br><span class="line">-rwxr-x---. 1 root root 50800 Dec  8  2011 &#x2F;usr&#x2F;sbin&#x2F;groupmems</span><br><span class="line">-rwxr-x---. 1 root root 61360 Dec  8  2011 &#x2F;usr&#x2F;sbin&#x2F;groupmod</span><br></pre></td></tr></table></figure>
<p><strong>一个人可以多个用户组 但是必须有一个主组</strong></p>
<ul>
<li>创建用户组 groupadd <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# groupadd bigdata</span><br><span class="line">[root@hadoop001 ~]# id ruoze</span><br><span class="line">uid=501(ruoze) gid=501(ruoze) groups=501(ruoze)</span><br></pre></td></tr></table></figure></li>
<li>添加用户组新成员为ruoze<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# usermod -a -G bigdata ruoze</span><br><span class="line">[root@hadoop001 ~]# id ruoze</span><br><span class="line">uid=501(ruoze) gid=501(ruoze) groups=501(ruoze),502(bigdata)</span><br></pre></td></tr></table></figure></li>
<li>修改bigdata为主组<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# usermod -g bigdata ruoze</span><br><span class="line">[root@hadoop001 ~]# id ruoze</span><br><span class="line">uid=501(ruoze) gid=502(bigdata) groups=502(bigdata) </span><br><span class="line">[root@hadoop001 ~]# usermod -a -G ruoze ruoze</span><br><span class="line">[root@hadoop001 ~]# id ruoze</span><br><span class="line">uid=501(ruoze) gid=502(bigdata) groups=502(bigdata),501(ruoze)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><strong>补充: CDH</strong><br>组件 账户密码登陆不上或者切换不了用户  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/passwd</span><br><span class="line">ruoze:x:501:502::/home/ruoze:/bin/false </span><br><span class="line">ruoze:x:501:502::/home/ruoze:/sbin/nologin</span><br><span class="line">这两个是造成不可以登录切换原因</span><br></pre></td></tr></table></figure>
<p>修改成<br><code>ruoze:x:501:502::/home/ruoze:/sbin/bin/bash</code> 可以切换</p>
<ul>
<li>修改家目录:<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">usermod -d /home/ruoze2  ruoze 修改家目录</span><br><span class="line">vi /etc/passwd   修改为bin/bash</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="17-设置passwd"><a href="#17-设置passwd" class="headerlink" title="17. 设置passwd"></a>17. 设置passwd</h4><p><code>passwd ruoze</code></p>
<h4 id="18-切换用户"><a href="#18-切换用户" class="headerlink" title="18.切换用户"></a>18.切换用户</h4><ul>
<li>su hadoop</li>
<li>su - hadoop</li>
<li><em>切换用户且切到该用户的家目录，且执行环境变量文件生效*</em></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# pwd</span><br><span class="line">/root</span><br><span class="line">[root@hadoop001 ~]# su hadoop</span><br><span class="line">[hadoop@hadoop001 root]$ pwd</span><br><span class="line">/root</span><br><span class="line">[hadoop@hadoop001 root]$ exit</span><br><span class="line">exit</span><br><span class="line">[root@hadoop001 ~]# </span><br><span class="line">[root@hadoop001 ~]# su - hadoop</span><br><span class="line">[hadoop@hadoop001 ~]$ </span><br><span class="line">[hadoop@hadoop001 ~]$ pwd</span><br><span class="line">/home/hadoop</span><br></pre></td></tr></table></figure>

<h5 id="19-sudo权限"><a href="#19-sudo权限" class="headerlink" title="19. sudo权限"></a>19. sudo权限</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/sudoers</span><br><span class="line">hadoop  ALL=(root)      NOPASSWD:ALL</span><br><span class="line">（给用户hadoop sudo权限）</span><br></pre></td></tr></table></figure>
<p>工作不可能给root账号的，要拥有sudo权限且不输入密码的普通用户（牵扯到部署环境）</p>
<h5 id="20-进程和端口号"><a href="#20-进程和端口号" class="headerlink" title="20. 进程和端口号"></a>20. 进程和端口号</h5><ul>
<li>ps -ef：把所有的进程打印出来<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ps -ef | grep tail  （tail的进程）</span><br><span class="line">root      2048  1962  0 21:11 pts/1    00:00:00 tail -F tail.log</span><br><span class="line">root      2053  1835  0 21:12 pts/0    00:00:00 grep tail</span><br><span class="line">[root@hadoop001 ~]# ps -ef|grep tail | grep -v grep （tail的进程排除grep tail）</span><br><span class="line">root      2048  1962  0 21:11 pts/1    00:00:00 tail -F tail.log</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root      2053  1835  0 21:12 pts&#x2F;0    00:00:00 grep tail</span><br><span class="line">进程用户    pid  父pid                   进程的内容</span><br></pre></td></tr></table></figure></li>
<li>杀死进程:<br><code>kill -9 pid</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ps -ef|grep tail</span><br><span class="line">root      2095  1962  0 21:17 pts/1    00:00:00 tail -F tail.log</span><br><span class="line">root      2098  2075  0 21:17 pts/2    00:00:00 tail -F tail1.log1</span><br><span class="line">root      2101  1835  0 21:17 pts/0    00:00:00 grep tail</span><br><span class="line">[root@hadoop001 ~]# kill -9 2095 2098  （同时杀死多个进程）</span><br><span class="line">[root@hadoop001 ~]# kill -9 $(pgrep -f tail)  （几十个进程一起杀）</span><br></pre></td></tr></table></figure>
<p><strong>提醒: 生产上假如非要执行kill杀进程，一定要确认清楚</strong><br><code>1.该进程是否真的杀？需求确认清楚</code><br><code>2.杀的进程是否你想要杀</code></p>
<ul>
<li>netstat端口号：<code>netstat -nlp</code></li>
</ul>
<p>找到ssh的进程的pid 1460，再通过pid找到该进程的端口号 22</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ps -ef|grep ssh</span><br><span class="line">root      1460     1  0 20:17 ?        00:00:00 /usr/sbin/sshd</span><br><span class="line">root      1831  1460  0 20:22 ?        00:00:00 sshd: root@pts/0,pts/1,pts/2</span><br><span class="line">root      2364  1835  0 21:22 pts/0    00:00:00 grep ssh</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# netstat -nlp|grep 1460</span><br><span class="line">tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      1460/sshd           </span><br><span class="line">tcp        0      0 :::22                       :::*                        LISTEN      1460/sshd  </span><br><span class="line">```         </span><br><span class="line">```shell</span><br><span class="line">[root@hadoop001 ~]# netstat -nlp|grep ssh  （也可以找到端口号，但是内容过多）</span><br><span class="line">tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      1460/sshd           </span><br><span class="line">tcp        0      0 127.0.0.1:6010              0.0.0.0:*                   LISTEN      1831/sshd           </span><br><span class="line">tcp        0      0 127.0.0.1:6011              0.0.0.0:*                   LISTEN      1831/sshd           </span><br><span class="line">tcp        0      0 127.0.0.1:6012              0.0.0.0:*                   LISTEN      1831/sshd           </span><br><span class="line">tcp        0      0 :::22                       :::*                        LISTEN      1460/sshd           </span><br><span class="line">tcp        0      0 ::1:6010                    :::*                        LISTEN      1831/sshd           </span><br><span class="line">tcp        0      0 ::1:6011                    :::*                        LISTEN      1831/sshd           </span><br><span class="line">tcp        0      0 ::1:6012                    :::*                        LISTEN      1831/sshd</span><br></pre></td></tr></table></figure>

<p><strong>某个服务的web</strong><br><em>正常流程：进程名称 –&gt; pid –&gt; port</em><br><code>1.port是否正确 是否变更</code><br><code>2.案例</code> </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ps -ef|grep http （http 所有的进程）</span><br><span class="line">[root@hadoop001 ~]# netstat -nlp|grep httpd</span><br><span class="line">tcp        0      0 :::80                       :::*                        LISTEN      2425/httpd  </span><br><span class="line">注意：80端口号可以省略，默认的访问  </span><br><span class="line">```     </span><br><span class="line">`3.端口号对外服务的ip地址，假如为127.0.0.1或localhost,只能在这台的机器上访问这个服务。一般这个地址为机器的ip或0.0.0.0 或 :::，表示对外的任意ip可以服务。`</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">[root@hadoop001 ~]# ping 127.0.0.1    (ping 看网络通不通)</span><br><span class="line">PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.</span><br><span class="line">64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.024 ms</span><br><span class="line">64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.028 ms</span><br><span class="line">64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.024 ms</span><br></pre></td></tr></table></figure>

<h4 id="21-find搜索"><a href="#21-find搜索" class="headerlink" title="21. find搜索"></a>21. find搜索</h4><ul>
<li><p><code>find / -name &#39;tail&#39;</code> 查找tail名称，全局匹配</p>
</li>
<li><p><code>find / -name &#39;*tail*&#39;</code> 查找包括tail，模糊匹配<br>以下都可以找到：abtail，abtailc，tailc</p>
</li>
<li><p><code>find /root -name &#39;*tail*&#39;</code> 特定目录，减少搜索范围，增加搜索效率</p>
</li>
<li><p><code>history | grep tail</code> 搜索有没有tail命令</p>
</li>
<li><p><code>ps -ef|grep tail</code>     搜索tail的进程</p>
</li>
</ul>
<h4 id="22-安装卸载"><a href="#22-安装卸载" class="headerlink" title="22. 安装卸载"></a>22. 安装卸载</h4><ul>
<li>yum安装<br><code>yum search httpd</code> 搜索安装的镜像语言<br><code>yum install httpd</code><br><code>yum install -y httpd</code> -y参数可以安装不用输入yes or no</li>
</ul>
<p><code>yum uninstall xxx</code> 错误的，不是卸载 <code>yum remove xxx</code>卸载</p>
<ul>
<li>rpm卸载<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# service httpd stop</span><br><span class="line">Stopping httpd:                                            [  OK  ]</span><br><span class="line">[root@hadoop001 ~]# yum remove mysql （有个问题可能会卸载我们需要的）</span><br><span class="line">[root@haizhu ~]# rpm -qa|grep mysql （查找出安装的mysql）</span><br><span class="line">mysql-8.0.26-1.module_el8.4.0+915+de215114.x86_64</span><br><span class="line">mysql-server-8.0.26-1.module_el8.4.0+915+de215114.x86_64</span><br><span class="line">mysql-common-8.0.26-1.module_el8.4.0+915+de215114.x86_64</span><br><span class="line">mysql-errmsg-8.0.26-1.module_el8.4.0+915+de215114.x86_64</span><br><span class="line">[root@hadoop001 ~]# rpm -e mysql-5.1.73-8.el6_8.x86_64 （卸载具体的安装）</span><br><span class="line"></span><br><span class="line">不校验依赖性</span><br><span class="line">--nodeps     do not verify package dependencies</span><br><span class="line">[root@hadoop001 ~]# rpm -e --nodeps httpd-2.2.15-69.el6.centos.x86_64 （不校验依赖性直接卸载）</span><br></pre></td></tr></table></figure>
<h4 id="23-which"><a href="#23-which" class="headerlink" title="23. which"></a>23. which</h4><code>$PATH</code> 找到所有命令<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# echo $PATH</span><br><span class="line">/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line"></span><br><span class="line">[root@hadoop001 ~]# which ls</span><br><span class="line">alias ls='ls --color=auto'</span><br><span class="line">	/bin/ls</span><br><span class="line">	</span><br><span class="line">[root@hadoop001 ~]# whereis ls</span><br><span class="line">ls: /bin/ls /usr/share/man/man1p/ls.1p.gz /usr/share/man/man1/ls.1.gz</span><br><span class="line">[root@hadoop001 ~]# which ls</span><br><span class="line">alias ls='ls --color=auto'</span><br><span class="line">	/bin/ls</span><br><span class="line">[root@hadoop001 ~]# cd /usr/lib64/qt-3.3/bin</span><br><span class="line">[root@hadoop001 bin]# ll</span><br><span class="line">total 4</span><br><span class="line">-rw-r--r--. 1 root root 4 Jun 19 22:22 ls</span><br><span class="line">[root@hadoop001 bin]# vi ls</span><br><span class="line">[root@hadoop001 bin]# chmod +x ls</span><br><span class="line">[root@hadoop001 bin]# which ls</span><br><span class="line">alias ls='ls --color=auto'</span><br><span class="line">	/usr/lib64/qt-3.3/bin/ls </span><br><span class="line">[root@hadoop001 bin]# ls</span><br><span class="line">ls</span><br><span class="line">[root@hadoop001 bin]# rm -f ls</span><br><span class="line">[root@hadoop001 bin]# which ls</span><br><span class="line">alias ls='ls --color=auto'</span><br><span class="line">	/bin/ls</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>例子：jdk环境部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 bin]# yum install lrzsz   （安装rzsz命令）</span><br><span class="line">[root@hadoop001 ~]# tar -xzvf jdk-8u45-linux-x64.gz  -C /usr/java/</span><br><span class="line">[root@hadoop001 ~]# cd /usr/java/</span><br><span class="line">[root@hadoop001 java]# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x. 8 uucp 143 4096 Apr 11  2015 jdk1.8.0_45</span><br><span class="line">[root@hadoop001 java]#</span><br></pre></td></tr></table></figure>

<p><code>1.java目录必须在/usr/java</code><br><code>2.用户用户组发生变更 必须修正</code><br><code>chown -R root:root  /usr/java/jdk1.8.0_45</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 java]# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x. 8 root root 4096 Apr 11  2015 jdk1.8.0_45</span><br><span class="line">[root@hadoop001 java]#</span><br></pre></td></tr></table></figure>
<p><code>3.配置全局环境变量</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# echo $PATH</span><br><span class="line">/usr/java/jdk1.8.0_45/bin:/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line">[root@hadoop001 ~]#</span><br></pre></td></tr></table></figure>

<h4 id="24-IP-访问和连接"><a href="#24-IP-访问和连接" class="headerlink" title="24.IP 访问和连接"></a>24.IP 访问和连接</h4><ul>
<li>IP连接<br><code>window: ipconfig</code><br><code>linux:  ifconfig</code></li>
</ul>
<p>服务对外 <code>ip:port</code> 访问的地址<br>有可能抛错误及解决方法:<br><code>1.timeout 超时</code><br>    <code>ping ip/hostname</code><br><code>2.connection refused 拒绝</code><br>    <code>telnet ip port</code> 注意没有冒号</p>
<p>Linux：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# yum install -y telnet</span><br><span class="line">Loaded plugins: fastestmirror, refresh-packagekit, security</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">Downloading Packages:</span><br><span class="line">telnet-0.17-48.el6.x86_64.rpm                      |  58 kB     00:00     </span><br><span class="line">Running rpm_check_debug</span><br><span class="line">Running Transaction Test</span><br><span class="line">Transaction Test Succeeded</span><br><span class="line">Running Transaction</span><br><span class="line">  Installing : 1:telnet-0.17-48.el6.x86_64                            1/1 </span><br><span class="line">  Verifying  : 1:telnet-0.17-48.el6.x86_64                            1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  telnet.x86_64 1:0.17-48.el6                                             </span><br><span class="line">Complete!</span><br><span class="line">[root@hadoop001 ~]# which telnet</span><br><span class="line">/usr/bin/telnet</span><br><span class="line">[root@hadoop001 ~]# telnet 192.168.137.130 80</span><br><span class="line">Trying 192.168.137.130...</span><br><span class="line">Connected to 192.168.137.130.</span><br><span class="line">Escape character is '^]'.</span><br><span class="line">^Z^C</span><br><span class="line">Connection closed by foreign host.</span><br><span class="line">[root@hadoop001 ~]# telnet 192.168.137.130 81</span><br><span class="line">Trying 192.168.137.130...</span><br><span class="line">telnet: connect to address 192.168.137.130: Connection refused</span><br></pre></td></tr></table></figure>

<ul>
<li>以hostname去连接</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# ping hadoop001</span><br><span class="line">ping: unknown host hadoop001  （unknown host映射关系没有配置）</span><br></pre></td></tr></table></figure>
<p>配置本地映射：IP hostname<br><code>linux :  /etc/hosts</code><br><code>window:  C:\Windows\System32\drivers\etc\hosts</code><br><code>\etc\hosts</code>直接添加<code>192.168.3.200 hadoop000</code></p>
<p><strong>注意：liunx前面的2行不要删，没有权限修改，直接复制一份桌面上，修改后拖拽覆盖即可</strong></p>
<ul>
<li><code>rz/sz</code>命令</li>
</ul>
<p><code>rz</code>命令         选择window的文件 传输<br><code>sz filename</code>命令将Linux的文件传输给window</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 bin]# yum install lrzsz</span><br></pre></td></tr></table></figure>

<h4 id="25-vi-vim基本使用"><a href="#25-vi-vim基本使用" class="headerlink" title="25. vi/vim基本使用"></a>25. vi/vim基本使用</h4><p>1）normal模式常用编辑<br><code>dd 删除当前行</code><br><code>dG 删除光标所在行及以下的所有行</code><br><code>ndd  删除光标所在行及以下的n-1行</code><br><code>gg 跳转到第一行的首字母</code><br><code>G 跳转到最后一行的首字母</code><br><code>shift+$  行尾</code><br><code>0  行首</code></p>
<p><strong><code>vi</code>清空这个文件:</strong></p>
<ul>
<li><code>gg+dG</code> 真正清空0字节 但是文件内容假如很大，加载肯定很慢 </li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo "" &gt; install.log  伪清空 1个字节</span><br><span class="line">echo '' &gt; install.log  伪清空 1个字节 </span><br><span class="line">-rw-r--r--. 1 root root         1 Jun 22 20:20 install.log</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cat /dev/null &gt; install.log</code>  真正清空0字节</li>
</ul>
<p>2）搜索:<br><code>尾行模式（:模式） /xxx  按n向下  N向上</code></p>
<p>3）想要跳转到最后1行编辑<br><code>G shift+$ shift+a/i</code></p>
<h4 id="26-权限"><a href="#26-权限" class="headerlink" title="26.权限"></a>26.权限</h4><ul>
<li><code>chown</code>  改变用户 用户组</li>
<li><code>chmod</code>  改变读写执</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">drwxr-xr-x. 2 root root      4096 Jun 12 22:41 Downloads</span><br><span class="line">-rw-r--r--. 1 root root      1012 Jun 15 21:46 error.log</span><br><span class="line">第一位字母: d文件夹 -文件 l连接</span><br><span class="line"></span><br><span class="line">r 读4</span><br><span class="line">w 写2</span><br><span class="line">x 执行 1 shell脚本</span><br><span class="line">- 0 没有任何权限 （注意是后面的-）</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rwx r-x r-x</span><br><span class="line">第一组 rwx 7 代表文件和文件夹所属的 用户的权限: 读写执</span><br><span class="line">第二组 r-x 5 代表文件和文件夹所属的 用户组的权限: 读执</span><br><span class="line">第三组 r-x 5 代表其他组的所有用户对这个文件或文件夹权限: 读执</span><br></pre></td></tr></table></figure>
<p> <strong>第一个<code>root</code> 用户 ，第二个<code>root</code> 用户组</strong></p>
<ul>
<li><p>文件的操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">test.log  </span><br><span class="line">rw-r--r-- 644 有读写的权限</span><br><span class="line">chmod 444 test.log (修改权限去掉写的权限)</span><br><span class="line">-r-r--r--</span><br><span class="line">root用户不管怎么修改权限都可以读写，其他用户按照命令权限来</span><br><span class="line">chmod u+x date.sh  (给date.sh可以执行的权限，注意用u+，否则每个用户都有可执行权限)</span><br></pre></td></tr></table></figure>
</li>
<li><p>文件夹操作 -R参数<br><code>-R参数: chown chmod</code><br><code>777 代表所有人都有最大权限 读写执</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chown -R jepson:jepson data</span><br><span class="line">chmod -R 777  data</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">字母和数字切换学会自己看</span><br><span class="line">rwxrwxr-x  775</span><br><span class="line">645 rw-r--r-x</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><em>工作上:</em></p>
<ul>
<li>不会给你root 假如给你root 慎重</li>
<li>假如给你账号  有sudo权限，无密码认证  也要慎重 </li>
<li>假如给你账号  就是普通账号，且没有sudo权限，一般只在自己的家目录做事情 和可以去的文件夹和文件</li>
<li>一台服务器 不可能只运行1个服务 很多服务<br>比如 mysql 需要用对应的用户去运行 比如mysqladmin用户<br>比如 hdfs 用hadoop用户<br>你们的用户能不能 su - mysqladmin? 一般是可以切</li>
</ul>
<h4 id="27-软连接"><a href="#27-软连接" class="headerlink" title="27. 软连接"></a>27. 软连接</h4><p><strong>好处：环境变量中的路径使用软连接，版本升级不用修改环境变量，直接删除在创建新的软连接</strong><br><code>ln -s hadoop-2.6.0 hadoop</code>创建软连接<br><code>rm -rf /opt/modouls/hadoop</code> 则是仅删除这个软链接，不会删除下面的内容</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[ruoze@hadoop001 ~]$ mkdir ruozedatav1.0</span><br><span class="line">[ruoze@hadoop001 ~]$ ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x. 2 ruoze bigdata 4096 Jun 22 21:35 ruozedatav1.0</span><br><span class="line">[ruoze@hadoop001 ~]$ ln -s  ruozedatav1.0  rz</span><br><span class="line">[ruoze@hadoop001 ~]$ ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x. 2 ruoze bigdata 4096 Jun 22 21:35 ruozedatav1.0</span><br><span class="line">lrwxrwxrwx. 1 ruoze bigdata   13 Jun 22 21:35 rz -&gt; ruozedatav1.0</span><br></pre></td></tr></table></figure>
<p><em>使用场景:</em></p>
<ul>
<li>多版本  版本升级，软连接可以减少代码修改和路径修改</li>
<li>硬盘<br><code>/home/ruoze/</code>  存储空间  100M 空间不够<br><code>/home/jepson/xxx</code> 存储空间  10T<br>把<code>/home/ruoze/</code> 移动到<code>/home/jepson/xxx</code><br><code>ln -s /home/jepson/xxx /home/ruoze/xxx</code></li>
<li><em>注意 ：所属的权限 用户 用户组的变化修正*</em></li>
</ul>
<h4 id="28-系统命令"><a href="#28-系统命令" class="headerlink" title="28. 系统命令"></a>28. 系统命令</h4><ul>
<li><p><code>df -h</code> 系统的磁盘</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]# df -h </span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        38G  3.9G   32G  11% /</span><br><span class="line">tmpfs          1000M   72K 1000M   1% /dev/shm</span><br><span class="line">/dev/sda1       194M   34M  151M  19% /boot</span><br><span class="line">/dev/sda3        2T  30G   999G  0.1% /data01 (额外挂载的盘)</span><br><span class="line">/dev/sda3        2T  30G   999G  0.1% /data02</span><br><span class="line">/dev/sda3        2T  30G   999G  0.1% /data03</span><br><span class="line">/dev/sda3        2T  30G   999G  0.1% /data04</span><br></pre></td></tr></table></figure></li>
<li><p><em>/ 根目录一般生产上 最多的是100G*</em></p>
</li>
<li><p><code>free -m</code> 内存</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@haizhu ~]# free -m</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7448        3033        2505           1        1909        4126</span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure>
<ul>
<li><code>top</code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">top - 12:25:32 up 2 days, 20:21,  1 user,  load average: 4.91, 5.02, 5.18</span><br><span class="line">Tasks: 117 total,   1 running, 116 sleeping,   0 stopped,   0 zombie</span><br><span class="line"><span class="meta">%</span><span class="bash">Cpu(s): 99.3 us,  0.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.7 hi,  0.0 si,  0.0 st</span></span><br><span class="line">MiB Mem :   7448.1 total,   2 02.9 free,   3035.0 used,   1910.2 buff/cache</span><br><span class="line">MiB Swap:      0.0 total,      0.0 free,      0.0 used.   4124.8 avail Mem</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">load average: 0.00, 0.00, 0.00</span><br><span class="line">			1min  5min 15min</span><br><span class="line">生产上 &lt;&#x3D;10 表示 系统还行</span><br><span class="line">	&gt;10 系统负载高 就是卡  	有可能服务问题 </span><br><span class="line">	cpu负载</span><br><span class="line">	0-200之间  内存条损坏 物理 原因重启服务器起不来</span><br></pre></td></tr></table></figure></li>
<li><code>shutdown -n now</code> 立即关机</li>
<li><code>reboot</code> 重启  等1min  连接机器</li>
</ul>
<h4 id="29-解压压缩"><a href="#29-解压压缩" class="headerlink" title="29 .解压压缩"></a>29 .解压压缩</h4><ul>
<li><p><code>zip</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ruozedata]# mkdir test</span><br><span class="line">[root@hadoop001 ruozedata]# cd test/</span><br><span class="line">[root@hadoop001 test]# touch 1.log</span><br><span class="line">[root@hadoop001 test]# cd ../</span><br><span class="line">[root@hadoop001 ruozedata]# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Jun 22 22:11 test</span><br><span class="line"></span><br><span class="line">[root@hadoop001 ruozedata]# zip -r  test.zip test/*    （压缩）</span><br><span class="line"></span><br><span class="line">  adding: test/1.log (stored 0%)</span><br><span class="line">[root@hadoop001 ruozedata]# ll</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Jun 22 22:11 test</span><br><span class="line">-rw-r--r--. 1 root root  170 Jun 22 22:12 test.zip</span><br><span class="line">[root@hadoop001 ruozedata]# rm -rf test</span><br><span class="line">[root@hadoop001 ruozedata]# ll</span><br><span class="line">total 4</span><br><span class="line">-rw-r--r--. 1 root root 170 Jun 22 22:12 test.zip</span><br><span class="line"></span><br><span class="line">[root@hadoop001 ruozedata]# unzip test.zip   （解压）</span><br><span class="line">Archive:  test.zip</span><br><span class="line"> extracting: test/1.log              </span><br><span class="line">[root@hadoop001 ruozedata]# ll</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Jun 22 22:12 test</span><br><span class="line">-rw-r--r--. 1 root root  170 Jun 22 22:12 test.zip</span><br><span class="line">[root@hadoop001 ruozedata]# ll test</span><br><span class="line">total 0</span><br><span class="line">-rw-r--r--. 1 root root 0 Jun 22 22:11 1.log</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>tar.gz</code><br><code>tar -xzvf xxx.tar.gz -C /opt/moduls xxx.tar.gz解压到/opt/moduls目录</code>  解压<br><code>tar -czvf xxx.tar.gz test/*</code> 压缩</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ruozedata]# ll</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Jun 22 22:12 test</span><br><span class="line">-rw-r--r--. 1 root root  170 Jun 22 22:12 test.zip</span><br><span class="line">[root@hadoop001 ruozedata]# tar -czvf test.tar.gz test/* </span><br><span class="line">test/1.log</span><br><span class="line">[root@hadoop001 ruozedata]# ll</span><br><span class="line">total 12</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Jun 22 22:12 test</span><br><span class="line">-rw-r--r--. 1 root root  114 Jun 22 22:16 test.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root  170 Jun 22 22:12 test.zip</span><br><span class="line">[root@hadoop001 ruozedata]# rm -rf test</span><br><span class="line">[root@hadoop001 ruozedata]# tar -xzvf test.tar.gz </span><br><span class="line">test/1.log</span><br></pre></td></tr></table></figure>

<h4 id="30-wget-下载"><a href="#30-wget-下载" class="headerlink" title="30. wget 下载"></a>30. wget 下载</h4><p><code>wget url</code>下载连接地址</p>
<h4 id="31-调度"><a href="#31-调度" class="headerlink" title="31. 调度"></a>31. 调度</h4><p><code>crontab</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 tmp]# crontab -e （新建crontab）</span><br><span class="line">[root@hadoop001 tmp]# crontab -l （查看crontab）</span><br><span class="line">* * * * * /tmp/date.sh &gt;&gt; /tmp/date.log </span><br><span class="line"></span><br><span class="line">分 小时 日 月 周</span><br><span class="line">* 表示 每</span><br></pre></td></tr></table></figure>
<ul>
<li>每隔2分钟<br><code>*/2 * * * *</code>（注意：<code>2/* 错误</code>）</li>
<li>每隔10s执行  <code>shell脚本 sleep 10s</code><br>1min 6次</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">[root@hadoop001 tmp]# cat date.sh </span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for((i=1;i&lt;=6;i++))</span><br><span class="line">do</span><br><span class="line">	echo "wwww.ruozedata.com"</span><br><span class="line">	date</span><br><span class="line">	sleep 10s</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">exit</span><br></pre></td></tr></table></figure>
<h4 id="32-后台执行"><a href="#32-后台执行" class="headerlink" title="32. 后台执行"></a>32. 后台执行</h4><p><code>./date.sh &amp;</code> 并不是真正后台执行  会话<br><code>nohup ./date.sh &amp;</code>  真正的后台执行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 tmp]# cat  nohup.out</span><br><span class="line">www.ruozedata.com</span><br><span class="line">Sat Jun 22 22:44:13 CST 2019</span><br><span class="line">[root@hadoop001 tmp]#</span><br></pre></td></tr></table></figure>
<p><code>nohup ./date.sh &gt;&gt; /tmp/date.log 2&gt;&amp;1 &amp;</code> </p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>new</title>
    <url>/2020/04/23/new/</url>
    <content><![CDATA[<center>欢迎来到spark Web
---
#### Spark Web
[spark官网](http://spark.apache.org/)

<a id="more"></a>

<h4 id="Spark-contet"><a href="#Spark-contet" class="headerlink" title="Spark contet"></a>Spark contet</h4><p>Spark Streaming provides a high-level abstraction called discretized stream or DStream, which represents a continuous stream of data. DStreams can be created either from input data streams from sources such as Kafka, Flume, and Kinesis, or by applying high-level operations on other DStreams. Internally, a DStream is represented as a sequence of RDDs.</p>
<p>This guide shows you how to start writing Spark Streaming programs with DStreams. You can write Spark Streaming programs in Scala, Java or Python (introduced in Spark 1.2), all of which are presented in this guide. You will find tabs throughout this guide that let you choose between code snippets of different languages.</p>
<p>Note: There are a few APIs that are either different or not available in Python. Throughout this guide, you will find the tag Python API highlighting these difference</p>
<h4 id="Spark-Code"><a href="#Spark-Code" class="headerlink" title="Spark Code"></a>Spark Code</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span>._ <span class="comment">// not necessary since Spark 1.3</span></span><br><span class="line"><span class="comment">// Count each word in each batch</span></span><br><span class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Print the first ten elements of each RDD generated in this DStream to the console</span></span><br><span class="line">wordCounts.print()</span><br></pre></td></tr></table></figure>

<h4 id="Spark-img"><a href="#Spark-img" class="headerlink" title="Spark img"></a>Spark img</h4><p><img src="./images/streaming-arch.png" alt="enter description here"></p>
<ul>
<li>1</li>
<li>2</li>
<li>3</li>
<li>4</li>
</ul>
<blockquote>
<p>Blockquote***==</p>
</blockquote>
<center>==**strong text**==</center>



<center>居中显示的文字

]]></content>
  </entry>
  <entry>
    <title>入党</title>
    <url>/2020/04/20/%E5%85%A5%E5%85%9A/</url>
    <content><![CDATA[<p>为党的根本工作路线;在党员的行动上，要求广大党员坚持人民利益高于一切，个人利益服从人民利益。此刻，我作为一名大学新生，在身边看到了许多大学生党员的先进行为。使我认识到作为一名大学班级团支部书，要更加党的思想理论知识，要在思想和行动上为其他团员同学作出表率，用实际行动争取早日加入伟大、正确而光荣的中</p>
<a id="more"></a>
<p>　　中国<em>是在中华民族处于最危险之际诞生的，她是顺应中国革命发展的必然产物，肩负起振兴中华的历史使命。经历了第一次、第二次国内革命战争、抗日战争、解放战争等艰苦斗争，中国</em>领导全国各族人民<em>了三座大山，建立了新中国。使饱经压迫和剥削之苦的中国人民翻身解放，成为了国家的主人。十一届三中全会以来，在</em>理论的指导下，在中国<em>的领导下，我国取得了举世瞩目的发展，生产力迅速发展，综合国力大大增强，人民生活水平大幅提高。我国社会主义初级阶段党的基本路线是：领导和团结全国各族人民，以经济建设为中心，坚持社会主义道路、坚持人民民主专政、坚持中国</em>的领导、坚持马列主义、*思想，坚持改革开放，自力更生，艰苦创业，为把我国建设成为富强、民主、礼貌的社会主义现代化国家而奋斗。</p>
<p>　　在大一开学之际，作为刚刚跨入大学的我，我就向党组织递交了，并参加了学校组织的业余党校学习。业余党校的学习过程中，在党组织和教师的安排下，我们进行了对理论学习的深入讨论，让我们入党进取分子之间相互交流，教师在我们讨论后更加深入地讲解了党的相关理论知识及怎样树立正确的。我认识到我应当从以下五方面端正我的入党动机：</p>
<p>　　第一，认真地学习马克思主义理论，马克思主义理论异常是马克思主义的党建理论，事实也证明，一个人对共产主义事业和*有了明确、深刻的认识，他的入党动机才会端正。</p>
<p>　　第二，经过实践的锻炼，不断端正自我的入党动机。马克思主义认识论告诉我们，人们正确认识，要经过实践认识再实践再认识的过程，并不断循环往复，才能正确的地获得。那里最重要的是我们的学习和社会实践。我仅有入党的迫切愿望还不够，还必须付诸于实际行动，在实践中不断用切身的体验来深化对党的认识，从而进一步端正自我的入党动机。经过在社会主义现代化建设中作出进取的贡献，来体会全心全意为人民服务的宗旨;以吃苦在前、享受在后的实际行动，来体会为共产主义不惜牺牲一切的高尚情操;经过学习优秀党员的模范事迹，优秀学生事迹来增强自我对党的感情，激励自我的行动，等等。一句话，就是经过身边活生生的、实实在在的、投身于建设有中国特色社会主义伟大事业的实践活动，来加深对党和共产主义事业的认识，强化正确的入党动机。端正入党动机，不是入党前一时的问题，而是一辈子的事情。</p>
]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>aa</tag>
      </tags>
  </entry>
  <entry>
    <title>hello</title>
    <url>/2020/04/20/word/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>aa</tag>
      </tags>
  </entry>
</search>
